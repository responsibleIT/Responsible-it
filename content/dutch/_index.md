---
title: Responsible IT
draft: false
tags: []
---

<!-- {{< intro title="Responsible IT Amsterdam" text= "Het lectoraat Responsible IT onderzoekt digitale technologie die goed is voor de mens, de maatschappij en de planeet. Het lectoraat werkt aan een grote uitdaging: betere digitale technologie. " >}}
                                                  -->

<!-- {{TOC}} -->

De Hogeschool van Amsterdam onderzoekt met het lectoraat Responsible IT welke rol maatschappelijke vraagstukken als gezondheid, onderwijs en mobiliteit moeten spelen bij de ontwikkeling van digitale technologie. Het onderzoek is een initiatief van lector Nanda Piersma en de Gemeente Amsterdam als een reactie op de toenemende invloed van Amerikaanse big tech bedrijven en Aziatische overheidstoepassingen van controlesystemen als gezichtsherkenning. 

Uitgangspunt van Responsible IT is het verwerven, gebruiken en delen van data op een verantwoorde manier, en het helpen van ontwikkelaars en instanties hierbij. Technologieën als algoritmes en kunstmatige intelligentie worden daarbij uitsluitend gebruikt op een mensgerichte manier en als deze transparant en betrouwbaar zijn. Privacy en autonomie zijn daarbij gewaarborgd en niemand wordt buitengesloten.

# Thema's: wat is goede digitale technologie?
## Robuust 
De techniek moet betrouwbaar werken. Niets is vervelender dan een computersysteem dat het niet doet, of de ene keer wel en de andere keer niet. Robuust betekent meer dan een werkend systeem. Het moet niet uitmaken met welke computer je werkt, een tablet, een Android smartphone of een Apple phone, of een desktop met groot scherm, het zou niet moeten uitmaken. Ook willen we future proof zijn, de techniek moet ook correct werken als er straks een nieuwe smartphone komt. 
## Eerlijk
De techniek moet voor iedereen hetzelfde werken. Een computersysteem is alleen eerlijk als iedereen dezelfde uitkomst krijgt als ze dezelfde kenmerken hebben. Dit is ook moeilijk voor mensen die beslissingen moeten nemen. Geautomatiseerde beslissingen van computer systemen kunnen zichzelf niet corrigeren als er oneerlijke situaties ontstaan, een mens wel. Omdat computers heel veel beslissingen tegelijkertijd kunnen nemen, loopt het snel uit de hand als er oneerlijke onderdelen in het systeem zitten. 
## Transparant
De techniek moet voor iedereen te begrijpen zijn.  De programmacode van een computersysteem voor de instructies die het uitvoert is voor de gewone mens niet te begrijpen. Er is dus aandacht nodig om duidelijk te maken wat het computersysteem precies doet, welke beslissing er wordt berekend, en hoe die beslissing wordt berekend. Als een computersysteem iets doet, zoals het verplaatsen van een pakket door een robot, dan willen we ook weten waarom iets wordt verplaatst. 
Voor beslissingen is transparantie erg belangrijk, alleen zo kun je zien of het systeem eerlijk is.
## Toegankelijk
De techniek moet door iedereen te gebruiken zijn. Een spiegel die te hoog hangt is niet te gebruiken. Een computer programma dat te technisch is ook niet. Vaak moeten mensen veel kennis hebben en veel dingen intypen om een computersysteem te laten werken. Met een goed doordacht en mensgericht ontwerp zijn digitale toepassingen voor meer mensen toegankelijk. Daarmee staan computersystemen in dienst van de mensen en niet de mensen in dienst van de systemen.
## Duurzaam
De techniek moet niet onnodig stroom vragen. Als de stroom uitvalt dan zullen we pas merken hoeveel computersystemen we eigenlijk hebben in het dagelijkse leven. Omdat de computersystemen zijn gebouwd in een tijd dat er genoeg fossiele energie leek te zijn, zijn de computers helemaal niet zuinig met energie. Dat kan zeker beter. 
Het lectoraat Responsible IT onderzoekt verantwoorde digitale technologie.

Goede digitale technologie doet recht aan publieke waarden, is van goede kwaliteit en bovenal gericht op de mens.

# Praktische handreikingen

Software wordt gemaakt door goed getrainde vakmensen. Die leveren graag een ook verantwoord product op. Het ontbreekt ze vaak aan kennis, methodes en gereedschap hoe. Het lectoraat onderzoekt en ontwikkelt praktijkgerichte voorbeelden, methodes en middelen. Hiermee kunnen IT professionals en hun leidinggevenden op een verantwoorde manier goede software ontwerpen en maken.

# Onderzoek bij het Lectoraat Responsible IT
Het lectoraat richt zich op methodes (voor) duiden, ontwerpen en implementeren van verantwoorde IT systemen. Praktische handreikingen voor ontwerpers en ontwikkelaars van digitale toepassingen die duiding geven aan wat verantwoord betekent.
(Kan zijn methode, modellen, toolkit, digitaal gereedschap, organisatievorm, inspiratie, codevoorbeeld, design patterns, datasets, boeken, manuals, lezingen, publicaties, installaties, onderwijs).

## Onderzoekslijnen
### Verantwoorde AI algoritmes 
Een algoritme is een automatische reeks computerinstructies die een beslissing van de mens kan nabootsen of ondersteunen. Kunstmatige intelligentie is een vorm van computerinstructies die kijken naar situaties uit het verleden (verzamelde data) en proberen de beslissingen die toen genomen zijn te gebruiken om te leren wat de beste beslissing is voor een toekomstige situatie. Die nieuwe situatie moet dus lijken op een gebeurtenis uit het verleden. Helaas was de beslissing uit het verleden niet altijd de juiste,  verantwoorde keuze. De computerinstructie (het algoritme) leert dus de onverantwoorde keuzes uit het verleden en gebruikt die om nu beslissingen te nemen. We onderzoeken of we kunnen herkennen wat een “foute” keuze is, door naar de data die gebruikt wordt te kijken, door te kijken naar de beslissingen die we proberen te automatiseren en door te kijken naar de manier waarop de instructies worden geprogrammeerd. We noemen de AI smart, of slim, wij onderzoeken of het ook verantwoord kan.
### Verantwoorde IT-systeemontwikkeling 
Net als de algoritmes zijn onze computer systemen niet voor iedereen eenvoudig te gebruiken. En vaak moet je een computer met een algoritme gebruiken om iets voor elkaar te krijgen: het aanvragen van een paspoort, de aankoop van een festival ticket bijvoorbeeld. Overal zien we computerschermen, met mensen die zitten te typen in plaats van in gesprek met ons te zijn. Het gebruik van computers heeft veel voordelen, we kunnen als mensen heel veel aan computers overlaten. Daarvoor moet het systeem wel goed werken, veilig zijn voor hackers, en te begrijpen. Wij werken met de bouwers van computersystemen, om bij het bouwen van de computersystemen al te werken met een goed ontwerp. Deze moeten makkelijk te gebruiken zijn, te begrijpen zijn en te vertrouwen. Als je op die manier werkt bij het bouwen van een computersysteem, dan zul je als bouwer andere keuzes maken. De systemen worden er beter van, verantwoorder.
### Duurzame IT 
Wij onderzoeken waar computersystemen precies energie voor nodig hebben en hoe dat met minder energie kan. Dat is niet alleen aan de computertechnici, ook de gebruikers van de systemen kunnen helpen om minder energie te gebruiken, bijvoorbeeld door hun foto’s niet allemaal te bewaren in een “cloud”. Het blijkt dat we niet goed weten hoeveel energie het nu precies kost om een instagram bericht te posten, of een nieuwsbrief te sturen. Wij proberen dit uit te rekenen. 
Binnen het lectoraat werkt een groep onderzoekers onder aansturing van associate lector Pascal Wiggers aan verantwoorde artificiële intelligentie.

# Community
Responsible IT bestaat uit een vaste kern van docent onderzoekers, en een los netwerk van mensen die we kennen als studenten, docenten, IT professionals, designers, kunstenaars en academici. Deze groep werkt samen met de Gemeente Amsterdam en andere opdrachtgevers aan praktische invulling van de Responsible IT thema's. 

Responsible IT is betrokken bij meerjarige landelijke onderzoeksprojecten met kennisinstituten, overheden en maatschappelijke organisaties.
Het lectoraat is opdrachtgever voor studentenprojecten in bachelor- en master-opleidingen van de HvA. De onderzoekers zijn nauw verbonden met de HvA opleidingen [HBO ICT]() en [Communication and Multimedia Design](). Responsible IT ontwikkelt onderwijs voor de [Master Applied AI]() en de HvA Minoren [Applied AI ]()en [Desinformatie]().






